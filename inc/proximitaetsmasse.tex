\chapter{Proximitätsmaße}

Um die Einteilung in möglichst homogene Gruppen vornehmen zu können, müssen die zu untersuchenden Objekte bezüglich ihrer zu beobachtenden Eigenschaften auf Ähnlichkeit untersucht werden. Die Wahl eines Proximitätsmaß für eine Clusteranalyse hängt maßgeblich davon ab, ob die Clusteranalyse Objekte oder Variablen zu klassifizieren versucht \citep[Vgl.][S. 196]{Bacher.2010}.

Nach \citet{Backhaus.2016} lassen sich zwei Arten von Proximitätsmaßen unterscheiden:

\begin{enumerate}
	\item \textit{Ähnlichkeitsmaße}: Diese Maße spiegeln die Ähnlichkeit zweier Objekte wieder. Je höher der zugewiesene Wert für zwei Objekte, desto höher ist auch ihre Ähnlichkeit.
	\item \textit{Distanzmaße} (auch \textit{Unähnlichkeitsmaße}): Diese drücken die Unähnlichkeit zweier Objekte aus. Je größer die angegebene Distanz, desto unähnlicher sind die Objekte, wobei eine Distanz von Null ausdrückt, dass die zwei Objekte hinsichtlich ihrer Klassifikationsmerkmale vollkommen identisch sind. Die Distanzmaße lassen sich als entgegengesetzter Pol der Ähnlichkeitsmaße auffassen, wobei diese Eigenschaft die Überführung beider Maße ineinander ermöglicht. (Eckey et al. \cite{Eckey.2002}, S. 205).
\end{enumerate}

Nach \citet[S. 200]{Bacher.2010} lassen sich alle Ähnlichkeitsmaße \textit{ä} durch 
\begin{equation}
u_{ij} = 1 - \ddot{a}_{ij} \quad \text{bzw.} \quad u_{g,g*} = 1- \ddot{a}_{g,g*}
\end{equation}
in Distanzmaße \textit{u} umwandeln.

Durch unterschiedliche Skalenniveaus der betrachteten Merkmale lassen sich eine Vielzahl von unterschiedlichen Proximitätsmaßen bestimmen.

\section{Proximitätsmaße für dichotome Merkmale}
Es kann von dichotomen Merkmalen (auch binären Merkmalen) gesprochen werden, wenn deren Modalitäten mit 0 und 1 kodiert werden; polytome Merkmale hingegen besitzen mehrere Ausprägungen \citep[Vgl.][S. 218]{Eckey.2002}. 

Um die Kombinationen der Merkmalsausprägungen bei einem Objekt- bzw. Variablenpaar zu definieren, kommt oft eine Kontingenztabelle (auch \textit{Vierfeldertafel}) zum Einsatz: \\

\begin{tabular}{cc|cc|c}
	& & \multicolumn{2}{c|}{Variable \textit{j} oder Objekt \textit{g*}} & \\ 
	& & 0 & 1 & $\sum$ \\ \hline
	\multirow{2}{*}{Variable \textit{i} oder Objekt \textit{g}} & 0 (Nichtbesitz) & a & b & a + b \\
	& 1 (Besitz) & c & d & c + d \\ \hline
	& $\sum$ & a + c & b + d & a + b + c + d = m \\ 
\end{tabular}
\bigskip
\\
Die Variablen \textit{a} und \textit{d} geben Auskunft über Übereinstimmungen. Die Variable \textit{a} gibt dabei Auskunft zur Übereinstimmung des Nichtbesitzes, dass bedeutet beide betrachteten Objekte besitzen das untersuchte Merkmal nicht. Die Variable \textit{d} gibt Auskunft zur Übereinstimmung des Besitzes, dass bedeutet beide betrachteten Objekte besitzen das untersuchte Merkmal. Die Variablen \textit{b} und \textit{c} geben Auskunft zur Nichtübereinstimmungen, dass heißt nur eines der Objekte besitzt das untersuchte Merkmal.

Ausgehend von \citet[S. 199/200]{Bacher.2010}
\begin{equation}
\ddot{a}_{ij} \quad \text{bzw.} \quad \ddot{a}_{g,g*} = \frac{\alpha \cdot a + \beta \cdot d}{\delta \cdot a + \beta \cdot d + \gamma \cdot (b + c)}
\end{equation}

lassen sich durch die unterschiedlichen Gewichtungsfaktoren $\alpha$, $\beta$, $\gamma$ und $\delta$ verschiedene Ähnlichkeitsmaße herleiten. Dabei gehen je nach Ähnlichkeitsmaß manche Variablen mehr und manche weniger in die Berechnung ein. Die Maße sind nach dem jeweiligen Entwickler benannt.
Nachfolgend sind einige Ähnlichkeitsmaße mitsamt ihrer Berechnung dargestellt. \\ 
\\
%\begin{tabular}{|l*{1}{|m{3.5cm}}|c*{1}{|m{3.5cm}}|p{10cm}|}
\begin{tabular}{|l|c|p{8cm}|}
	\hline
	\rowcolor{babyblueeyes}Ähnlichkeitsmaß & Berechnungsformel & Eigenschaften \\ \hline
	\rowcolor{beaublue}Jaccard I & $\frac{0 \cdot \textit{a} + 1 \cdot \textit{d}}{1 \cdot \textit{a} + 1 \cdot \textit{d} + 1 \cdot (\textit{b} + \textit{c})} $ & Gemeinsamer Nichtbesitz geht nicht in Berechnung ein \\ \hline
	\rowcolor{beaublue}Dice & $ \frac{0 \cdot \textit{a} + 2 \cdot \textit{d}}{1 \cdot \textit{a} + 1 \cdot \textit{d} + 1 \cdot (\textit{b} + \textit{c})} $ & Gemeinsamer Nichtbesitz geht nicht in Berechnung ein, gemeinsamer Besitz doppelt \\ \hline
	\rowcolor{beaublue}Sokal \& Sneath I & $ \frac{0 \cdot \textit{a} + 1 \cdot \textit{d}}{1 \cdot \textit{a} + 1 \cdot \textit{d} + 2 \cdot (\textit{b} + \textit{c})} $ & Gemeinsamer Nichtbesitz geht nicht in Berechnung ein, Nichtübereinstimmung doppelt \\ \hline
	\rowcolor{beaublue}Russel \& Rao & $ \frac{0 \cdot \textit{a} + 1 \cdot \textit{d}}{1 \cdot \textit{a} + 1 \cdot \textit{d} + 1 \cdot (\textit{b} + \textit{c})} $ & Gemeinsamer Nichtbesitz wird nicht als Ähnlichkeit betrachtet, geht aber in den Nenner ein \\ \hline
	\rowcolor{beaublue}Simple-Matching & $ \frac{1 \cdot \textit{a} + 1 \cdot \textit{d}}{1 \cdot \textit{a} + 1 \cdot \textit{d} + 1 \cdot (\textit{b} + \textit{c})} $ & Alles wird gleich gewichtet \\ \hline
	\rowcolor{beaublue}Sokal \& Sneath II & $ \frac{2 \cdot (\textit{a} + \textit{d})}{2 \cdot (\textit{a} + \textit{d}) + 1 \cdot (\textit{b} + \textit{c})} $ & Übereinstimmungen werden doppelt gewichtet \\ \hline
	\rowcolor{beaublue}Rogers \& Tanimoto & $ \frac{1 \cdot \textit{a} + 1 \cdot \textit{d}}{1 \cdot a + 1 \cdot \textit{d} + 2 \cdot (\textit{b} + \textit{c})} $ & Nichtübereinstimmung wird doppelt gewichtet \\ \hline
\end{tabular}
	

\section{Proximitätsmaße für polytome Merkmale}
Polytome Merkmale können auf einem nominalen oder ordinalen Skalenniveau gemessen werden und immer anhand einer Dichotomisierung durch mehrere dichotome Merkmale (sogenannte Dummy-Variablen) ersetzt werden. Ein Merkmal mit \textit{r} Merkmalsausprägungen erfordert somit \textit{r} Dummy-Variablen \citep[Vgl.][S. 159]{Bankhofer.2008}. Hierbei ist aber vor allem darauf zu achten, dass ein erheblicher Informationsverlust bei der Dichotomisierung ordinal skalierter Merkmale in Kauf genommen werden muss. In diesem Fall würde sich eher eine Distanzmessung über die Rangdistanz anbieten, die vorteilhaft anwendbar ist, sofern die Ränge als Intervallskala interpretiert werden und die meisten Merkmale sich in ihren Ausprägungen unterscheiden \citep[Vgl.][S. 225]{Eckey.2002}.

\section{Proximitätsmaße für hierarchische Merkmale}

Bei hierarchischen Merkmalen wird von einzelnen Hierarchieebenen ausgegangen, denen ein Wert stellvertretend für die Aggregation der Hierarchie zugewiesen wird. Ausgehend von einer Baumstruktur der verästelten hierarchischen Merkmale wird untersucht, auf welcher Hierarchieebene zwei Merkmalsausprägungen zusammentreffen. Anhand dieser Beobachtung kann ihnen dann eine spezifische Distanz zugeordnet werden \citep[Vgl.][S. 160]{Bankhofer.2008}.

\section{Proximitätsmaße für quantitative Merkmale}
Bei einer objektorientierten Clusteranalyse wird vor allem von Distanzmaßen ausgegangen, die sich aus der verallgemeinerten Minkowski-Metrik ableiten. In der Literatur wird oft auch \textit{q} = \textit{r} gesetzt. Hier spricht man von der gewöhnlichen Minkowski-Metrik \citep[Vgl.][S. 219]{Bacher.2010}:

\begin{equation}
d(q,r)_{g,g*} = 
\left[	\sum_{i} |x_{gi} - x_{g*i}|^r	\right]^\frac{1}{q}
\end{equation}

Anhand der Parameter lassen sich verschiedene Distanzmaße für einzelne Merkmale unterscheiden \citep[Vgl.][S. 219]{Bacher.2010}:
\begin{center}
\begin{tabular}{lcll}
	\textit{r} = 1 & und & \textit{q} = 1 & für die City-Block-Distanz \\
	\textit{r} = 2 & und & \textit{q} = 2 & für die euklidische Distanz \\
	\textit{r} = 2 & und & \textit{q} = 1 & für die quadrierte euklidische Distanz \\
	\textit{r} = $\infty$ & und & \textit{q} = $\infty$ & für die Chebychev-Distanz \\
\end{tabular}
\end{center}

Der Parameter \textit{r} bestimmt, wie stark größere Unterschiede in wenigen Variablen bzw. wie kleinere Unterschiede in vielen Variablen Einfluss nehmen. Beispielsweise gehen bei der City-Block-Distanz Merkmalswertdifferenzen proportional zu ihrem Ausmaß in die Objektdistanz ein, während Merkmalswertdifferenzen bei der euklidischen Distanz einen überproportional großen Einfluss besitzen \citep[Vgl.][S. 212]{Eckey.2002}. Die Verwendung des Namens $L_p$-Distanzen ist durchaus üblich. Die Unterscheidung erfolgt hierbei durch den Parameter \textit{p} mit \textit{p} = \textit{q} = \textit{r}, wodurch die quadrierte euklidische Distanz für gewöhnlich nicht zu den $L_p$-Distanzen gezählt wird. \\

Des weiteren spielt im Falle von hoch korrelierten Merkmalen die Malahanobis-Distanz eine wichtige Rolle, da sie Korrelationen und Varianzen zwischen den Variablen beseitigt:

\begin{equation}
MAHA(x_{g},x_{g*}) = (x_{g} - x_{g*}) \cdot S^{-1} \cdot (x_{g} - x_{g*})
\end{equation}
mit $x_{g}$ und $x_{g*}$ als Merkmalsvektoren der Objekte \textit{g} bzw. \textit{g*}. $S^{-1}$ bezeichnet die Inverse der zugrundeliegenden Kovarianzmatrix (Vgl. \citealt[S. 339]{Bacher.2010} und \citealt[S. 168]{Bankhofer.2008}). Die Zwischenschaltung der inversen Kovarianz bewirkt hier, dass der Größenordnungseffekt beseitigt wird, da Merkmale mit hohen Kovarianzen und/oder hohen Varianzen abgewichtet werden. Dies kann bei Distanzmaßen, die aus der Minkowski-Metrik errechnet werden, nur durch eine vorherige Standardisierung erfolgen \citep[Vgl.][S. 214]{Eckey.2002}.
