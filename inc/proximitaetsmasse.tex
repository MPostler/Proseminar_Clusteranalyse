\chapter{Proximitätsmaße}

Um die Einteilung in möglichst homogene Gruppen vornehmen zu können, müssen die zu untersuchenden Objekte bezüglich ihrer zu beobachtenden Eigenschaften auf Ähnlichkeit bzw. Unähnlichkeit untersucht werden. Die Wahl eines Proximitätsmaß für eine Clusteranalyse hängt maßgeblich davon ab, ob die Clusteranalyse Objekte oder Variablen zu klassifizieren versucht \citep[Vgl.][S. 196]{Bacher.2010}.

Nach \citet{Backhaus.2016} lassen sich zwei Arten von Proximitätsmaßen unterscheiden:

\begin{enumerate}
	\item \textit{Ähnlichkeitsmaße}: Diese Maße spiegeln die Ähnlichkeit zweier Objekte wider. Je höher der zugewiesene Wert für zwei Objekte, desto höher ist auch ihre Ähnlichkeit.
	\item \textit{Unähnlichkeitsmaße} (auch \textit{Distanzmaße}): Diese drücken die Unähnlichkeit zweier Objekte aus. Je größer die angegebene Distanz, desto unähnlicher sind die Objekte, wobei eine Distanz von Null ausdrückt, dass die zwei Objekte hinsichtlich ihrer Klassifikationsmerkmale vollkommen identisch sind.
\end{enumerate}
Die Unähnlichkeitsmaße lassen sich als entgegengesetzter Pol der Ähnlichkeitsmaße auffassen, wobei diese Eigenschaft die Überführung beider Maße ineinander ermöglicht \citep[Vgl.][S. 205]{Eckey.2002}. Nach \citet[S. 200]{Bacher.2010} lassen sich alle Ähnlichkeitsmaße \textit{ä} für zwei Variablen $i$ und $j$ bzw. zwei Objekte $g$ und $g*$ durch 
\begin{equation}
u_{ij} = 1 - \ddot{a}_{ij} \quad \text{bzw.} \quad u_{g,g*} = 1- \ddot{a}_{g,g*}
\end{equation}
in Distanzmaße \textit{u} umwandeln. Durch unterschiedliche Skalenniveaus der betrachteten Merkmale lassen sich nun eine Vielzahl von unterschiedlichen Proximitätsmaßen bestimmen.

\section{Proximitätsmaße für dichotome Merkmale}
Es kann von dichotomen Merkmalen (auch binären Merkmalen) gesprochen werden, wenn deren Modalitäten mit 0 und 1 kodiert werden; polytome Merkmale hingegen besitzen mehrere Ausprägungen \citep[Vgl.][S. 218]{Eckey.2002}. 

Um die Kombinationen der Merkmalsausprägungen bei einem Variablenpaar $i,j$ bzw. Objektpaar $g,g*$ zu definieren, kommt oft eine Kontingenztabelle (auch Vierfeldertafel) zum Einsatz: \\

\begin{tabular}{cl|cc|c}
	& & \multicolumn{2}{c|}{Variable \textit{j} oder Objekt \textit{g*}} & \\ 
	& & 0 & 1 & $\sum$ \\ \hline
	\multirow{2}{*}{Variable \textit{i} oder Objekt \textit{g}} & 0 (Nichtbesitz) & a & b & a + b \\
	& 1 (Besitz) & c & d & c + d \\ \hline
	& $\sum$ & a + c & b + d & a + b + c + d = m \\ 
\end{tabular}
\bigskip
\\
Die Variablen \textit{a} und \textit{d} geben Auskunft über Übereinstimmungen. Die Variable \textit{a} über die Übereinstimmung des Nichtbesitzes (beide betrachteten Objekte besitzen das untersuchte Merkmal nicht), während die Variable \textit{d} Auskunft über Übereinstimmung des Besitzes (beide betrachteten Objekte besitzen das untersuchte Merkmal) gibt. Die Variablen \textit{b} und \textit{c} geben Auskunft über Nichtübereinstimmungen; nur eines der Objekte besitzt das untersuchte Merkmal.

\begin{equation}
\ddot{a}_{ij} \quad \text{bzw.} \quad \ddot{a}_{g,g*} = \frac{\alpha \cdot a + \beta \cdot d}{\delta \cdot a + \beta \cdot d + \gamma \cdot (b + c)}
\end{equation}

Ausgehend von \citet[S. 199/200]{Bacher.2010} lassen sich durch die unterschiedlichen Gewichtungsfaktoren $\alpha$, $\beta$, $\gamma$ und $\delta$ und die zuvor vorgestellten Variablen verschiedene \linebreak Ähnlichkeitsmaße herleiten. Dabei gehen je nach Ähnlichkeitsmaß manche Variablen mehr und manche weniger in die Berechnung ein. Die Maße sind nach dem jeweiligen Entwickler benannt und die Nummerierungszusätze werden verwendet, wenn mehrere Maße erarbeitet wurden.
Nachfolgend sind einige Ähnlichkeitsmaße mitsamt ihrer Berechnung und typischen Eigenschaften dargestellt. \\ 
\\
\begin{tabular}{|l|c|p{8cm}|}
	\hline
	\rowcolor{babyblueeyes}Ähnlichkeitsmaß & Berechnungsformel & Eigenschaften \\ \hline
	\rowcolor{beaublue}Jaccard I & $\frac{0 \cdot \textit{a} + 1 \cdot \textit{d}}{1 \cdot \textit{a} + 1 \cdot \textit{d} + 1 \cdot (\textit{b} + \textit{c})} $ & Gemeinsamer Nichtbesitz geht nicht in Berechnung ein \\ \hline
	\rowcolor{beaublue}Dice & $ \frac{0 \cdot \textit{a} + 2 \cdot \textit{d}}{1 \cdot \textit{a} + 1 \cdot \textit{d} + 1 \cdot (\textit{b} + \textit{c})} $ & Gemeinsamer Nichtbesitz geht nicht in Berechnung ein, gemeinsamer Besitz doppelt \\ \hline
	\rowcolor{beaublue}Sokal \& Sneath I & $ \frac{0 \cdot \textit{a} + 1 \cdot \textit{d}}{1 \cdot \textit{a} + 1 \cdot \textit{d} + 2 \cdot (\textit{b} + \textit{c})} $ & Gemeinsamer Nichtbesitz geht nicht in Berechnung ein, Nichtübereinstimmung doppelt \\ \hline
	\rowcolor{beaublue}Russel \& Rao & $ \frac{0 \cdot \textit{a} + 1 \cdot \textit{d}}{1 \cdot \textit{a} + 1 \cdot \textit{d} + 1 \cdot (\textit{b} + \textit{c})} $ & Gemeinsamer Nichtbesitz wird nicht als Ähnlichkeit betrachtet, geht aber in den Nenner ein \\ \hline
	\rowcolor{beaublue}Simple-Matching & $ \frac{1 \cdot \textit{a} + 1 \cdot \textit{d}}{1 \cdot \textit{a} + 1 \cdot \textit{d} + 1 \cdot (\textit{b} + \textit{c})} $ & Alles wird gleich gewichtet \\ \hline
	\rowcolor{beaublue}Sokal \& Sneath II & $ \frac{2 \cdot (\textit{a} + \textit{d})}{2 \cdot (\textit{a} + \textit{d}) + 1 \cdot (\textit{b} + \textit{c})} $ & Übereinstimmungen werden doppelt gewichtet \\ \hline
	\rowcolor{beaublue}Rogers \& Tanimoto & $ \frac{1 \cdot \textit{a} + 1 \cdot \textit{d}}{1 \cdot a + 1 \cdot \textit{d} + 2 \cdot (\textit{b} + \textit{c})} $ & Nichtübereinstimmung wird doppelt gewichtet \\ \hline
\end{tabular}

\section{Proximitätsmaße für polytome Merkmale}
Polytome Merkmale können auf einem nominalen oder ordinalen Skalenniveau gemessen werden und immer anhand einer Dichotomisierung durch mehrere dichotome Merkmale (sogenannte Dummy-Variablen) ersetzt werden. Ein Merkmal mit \textit{r} Merkmalsausprägungen erfordert somit \textit{r} Dummy-Variablen \citep[Vgl.][S. 159]{Bankhofer.2008}. Hierbei ist aber vor allem darauf zu achten, dass ein erheblicher Informationsverlust bei der Dichotomisierung ordinal skalierter Merkmale in Kauf genommen werden muss. In diesem Fall würde sich eher eine Distanzmessung über die Rangdistanz anbieten, die vorteilhaft anwendbar ist, sofern die Ränge als Intervallskala interpretiert werden und die meisten Merkmale sich in ihren Ausprägungen unterscheiden \citep[Vgl.][S. 225]{Eckey.2002}.

\section{Proximitätsmaße für hierarchische Merkmale}
Bei diesen Merkmalen wird von einzelnen Hierarchieebenen ausgegangen, denen ein Wert stellvertretend für die Aggregation der Hierarchie zugewiesen wird. Ausgehend von einer Baumstruktur der verästelten hierarchischen Merkmale wird untersucht, auf welcher Hierarchieebene zwei Merkmalsausprägungen zusammentreffen. Anhand dieser Beobachtung kann ihnen dann eine spezifische Distanz zugeordnet werden \citep[Vgl.][S. 160]{Bankhofer.2008}. Ein Beispiel hierfür wäre die Zugehörigkeit von zwei Studiengängen zu Fakultäten. Will man nun herausfinden, welche Distanz anhand dieser Zuordnung zwischen den beiden Studiengängen existiert, kann untersucht werden, ob die zwei Studiengänge der selben oder unterschiedlichen Fakultäten angehören. Je nach ihrem Zusammentreffen auf Fakultäts- oder erst auf Universitätsebene (sie gehören unterschiedlichen Fakultäten an) werden ihnen unterschiedliche Distanzen zugewiesen.

\section{Proximitätsmaße für quantitative Merkmale}
Bei einer objektorientierten Clusteranalyse wird vor allem von Distanzmaßen ausgegangen, die sich aus der verallgemeinerten bzw. gewöhnlichen Minkowski-Metrik ableiten \citep[Vgl.][S. 219]{Bacher.2010}:

\begin{equation}
d(q,r)_{g,g*} = 
\left[	\sum_{i} |x_{gi} - x_{g*i}|^r	\right]^\frac{1}{q}
\end{equation}

Man spricht von einer gewöhnlichen Minkowski-Metrik, wenn \textit{q} = \textit{r} gesetzt wird. Anhand der Parameter lassen sich verschiedene Distanzmaße für einzelne Merkmale unterscheiden:
\begin{center}
\begin{tabular}{lcll}
	\textit{r} = 1 & und & \textit{q} = 1 & für die City-Block-Distanz \\
	\textit{r} = 2 & und & \textit{q} = 2 & für die euklidische Distanz \\
	\textit{r} = 2 & und & \textit{q} = 1 & für die quadrierte euklidische Distanz \\
	\textit{r} = $\infty$ & und & \textit{q} = $\infty$ & für die Chebychev-Distanz \\
\end{tabular}
\end{center}

Der Parameter \textit{r} bestimmt, wie stark größere Unterschiede in wenigen Variablen bzw. wie kleinere Unterschiede in vielen Variablen Einfluss nehmen. Beispielsweise gehen bei der City-Block-Distanz Merkmalswertdifferenzen proportional zu ihrem Ausmaß in die Objektdistanz ein, während Merkmalswertdifferenzen bei der euklidischen Distanz einen überproportional großen Einfluss besitzen, da bei zunehmendem $|x_{gi} - x_{g*i}|$ die $r$-ten Potenzen umso schneller anwachsen, je größer $r$ ist (Vgl. \citealt[S. 212]{Eckey.2002} und \citealt[S. 40]{Bock.1974}). 

Die Verwendung des Namens $L_p$-Distanzmaße für die Maße aus der Minkowski-Metrik ist in der Literatur ebenfalls durchaus üblich. Die Unterscheidung erfolgt hierbei durch den Parameter \textit{p} mit \textit{p} = \textit{q} = \textit{r}, wodurch die quadrierte euklidische Distanz aufgrund ihrer voneinander verschiedenen Parameterwerten für gewöhnlich nicht zu den $L_p$-Distanzen gezählt wird. \\

Da zwei hoch korrelierte Merkmale bezüglich der Ähnlichkeit der Objekte in etwa die selbe Information liefern und Distanzmaße, die aus der Minkowski-Metrik stammen, diese Information doppelt berücksichtigen würden, wurde von Prasanta Chandra Malahanobis ein weiteres Distanzmaß ermittelt. Die Malahanobis-Distanz beseitigt Korrelationen und Varianzen zwischen den Variablen:

\begin{equation}
MAHA(x_{g},x_{g*}) = (x_{g} - x_{g*}) \cdot S^{-1} \cdot (x_{g} - x_{g*})
\end{equation}
mit $x_{g}$ und $x_{g*}$ als Merkmalsvektoren der Objekte \textit{g} bzw. \textit{g*}. $S^{-1}$ bezeichnet die Inverse der zugrundeliegenden Kovarianzmatrix (Vgl. \citealt[S. 339]{Bacher.2010} und \citealt[S. 168]{Bankhofer.2008}). Die Zwischenschaltung der inversen Kovarianz bewirkt hier, dass der Größenordnungseffekt beseitigt wird, da Merkmale mit hohen Kovarianzen und/oder hohen Varianzen abgewichtet werden. Dies kann bei Distanzmaßen, die aus der Minkowski-Metrik errechnet werden, nur durch eine vorherige Standardisierung erfolgen \citep[Vgl.][S. 214]{Eckey.2002}. Ausgehend von \citet[S. 43/44]{Bock.1974} besitzt die Malahanobis-Distanz besondere Eigenschaften wie Skaleninvarianz, die dazu führen, dass eine etwaige Korrelation der Merkmale eliminiert wird und somit keinen Einfluss mehr auf die Distanzmatrix ausübt. 
